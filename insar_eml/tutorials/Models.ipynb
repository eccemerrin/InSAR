{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db0588a8",
   "metadata": {},
   "source": [
    "# MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265143b3",
   "metadata": {},
   "source": [
    "In this notebook, we are going to explain the proposed models. All the information about the models can be found in the cell above the model code. All the models below will be in .py files in the same repo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf597a8",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f6815ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5d3315",
   "metadata": {},
   "source": [
    "## Insar Model (Default Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e537974",
   "metadata": {},
   "source": [
    "This model is reproduced from the paper [Autonomous extraction of millimeter-scale deformation in InSAR time series using deep learning](https://www.nature.com/articles/s41467-021-26254-3). In this model, we followed the explanation of the model given in the paper but the number of parameters does not match. It is the default model we use. Number of pixels can be changed by changing the parameter \"num_pixels\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41a320b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This architecture is our default architecture.\n",
    "def insar_model(num_pixels = 40):\n",
    "    model_input = tf.keras.Input(shape=(9, num_pixels, num_pixels, 1))\n",
    "    topology_input = tf.keras.Input(shape=(1, num_pixels, num_pixels, 1))\n",
    "\n",
    "    x = tf.keras.layers.Conv3D(64, (2,3,3), (1, 1, 1), padding = \"same\")(model_input) #1216\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Conv3D(64, (2,3,3), (1, 1, 1), padding = \"same\")(x) #73792\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Conv3D(64, (2,3,3), (1, 1, 1), padding = \"same\")(x) #73792\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Conv3D(64, (2,3,3), (1, 1, 1), padding=\"same\")(x) #73792\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.MaxPooling3D((3,1,1))(x)\n",
    "    x = tf.keras.layers.Conv3D(64, (2,3,3), (1, 1, 1), padding = \"same\")(x) #73792\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.MaxPooling3D((3,1,1))(x)\n",
    "\n",
    "    combined = tf.concat([x, topology_input], axis=-1)\n",
    "\n",
    "    y = tf.keras.layers.Conv3DTranspose(65, (1,3,3), padding = \"same\")(combined) #37504\n",
    "    y = tf.keras.layers.LeakyReLU()(y)\n",
    "\n",
    "    y = tf.keras.layers.Conv3DTranspose(64, (1,3,3),  padding = \"same\")(y) #36928\n",
    "    y = tf.keras.layers.LeakyReLU()(y)\n",
    "    y = tf.keras.layers.Conv3DTranspose(64, (1,3,3), padding = \"same\")(y)  #36928\n",
    "    y = tf.keras.layers.LeakyReLU()(y)\n",
    "    y = tf.keras.layers.Conv3DTranspose(64, (1,3,3), padding = \"same\")(y)  #36928\n",
    "    y = tf.keras.layers.LeakyReLU()(y)\n",
    "    y = tf.keras.layers.Conv3DTranspose(64, (1,3,3), padding = \"same\")(y)  #36928\n",
    "    y = tf.keras.layers.LeakyReLU()(y)\n",
    "    y = tf.keras.layers.Conv3DTranspose(1, (1, 3, 3), padding=\"same\")(y)  # 577\n",
    "    y = tf.keras.layers.Activation('linear')(y)\n",
    "    model_output = tf.keras.layers.Reshape((num_pixels, num_pixels, 1))(y)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = [model_input, topology_input], outputs = model_output, name=\"insar_model\")\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13aa034",
   "metadata": {},
   "source": [
    "## Insar Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943ec2db",
   "metadata": {},
   "source": [
    "This model is reproduced from the paper [Autonomous extraction of millimeter-scale deformation in InSAR time series using deep learning](https://www.nature.com/articles/s41467-021-26254-3). In this model, we added one more encoding convolutional layer to the previous model in order to match the number of parameters given in the paper. It does not have the same number of parameters, exceeds, but it is the one that has the closest number of parameters to the paper. It is the default model we use. Number of pixels can be changed by changing the parameter \"num_pixels\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f71a0bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insar_model_2(num_pixels = 40):\n",
    "    model_input = tf.keras.Input(shape=(9, num_pixels, num_pixels, 1))\n",
    "    topology_input = tf.keras.Input(shape=(1, num_pixels, num_pixels, 1))\n",
    "\n",
    "    x = tf.keras.layers.Conv3D(64, (2, 3, 3), (1, 1, 1), padding=\"same\")(model_input)  # 1216\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Conv3D(64, (2, 3, 3), (1, 1, 1), padding=\"same\")(x)  # 73792\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Conv3D(64, (2, 3, 3), (1, 1, 1), padding=\"same\")(x)  # 73792\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Conv3D(64, (2, 3, 3), (1, 1, 1), padding=\"same\")(x)  # 73792\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.MaxPooling3D((3, 1, 1))(x)\n",
    "    x = tf.keras.layers.Conv3D(64, (2, 3, 3), (1, 1, 1), padding=\"same\")(x)  # 73792\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Conv3D(64, (2, 3, 3), (1, 1, 1), padding=\"same\")(x)  # 73792\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.MaxPooling3D((3, 1, 1))(x)\n",
    "\n",
    "    combined = tf.concat([x, topology_input], axis=-1)\n",
    "\n",
    "    y = tf.keras.layers.Conv3DTranspose(65, (1, 3, 3), padding=\"same\")(combined)  # 37504\n",
    "    y = tf.keras.layers.LeakyReLU()(y)\n",
    "\n",
    "    y = tf.keras.layers.Conv3DTranspose(64, (1, 3, 3), padding=\"same\")(y)  # 36928\n",
    "    y = tf.keras.layers.LeakyReLU()(y)\n",
    "    y = tf.keras.layers.Conv3DTranspose(64, (1, 3, 3), padding=\"same\")(y)  # 36928\n",
    "    y = tf.keras.layers.LeakyReLU()(y)\n",
    "    y = tf.keras.layers.Conv3DTranspose(64, (1, 3, 3), padding=\"same\")(y)  # 36928\n",
    "    y = tf.keras.layers.LeakyReLU()(y)\n",
    "    y = tf.keras.layers.Conv3DTranspose(1, (1, 3, 3), padding=\"same\")(y)  # 577\n",
    "    y = tf.keras.layers.Activation('linear')(y)\n",
    "    model_output = tf.keras.layers.Reshape((num_pixels, num_pixels, 1))(y)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[model_input, topology_input], outputs=model_output, name=\"model1\")\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb0d850",
   "metadata": {},
   "source": [
    "## Variational Autoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17257779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_model():\n",
    "\n",
    "    class Sampling(tf.keras.layers.Layer):\n",
    "         #Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\n",
    "        def call(self, inputs):\n",
    "             z_mean, z_log_var = inputs\n",
    "             batch = tf.shape(z_mean)[0]\n",
    "             dim = tf.shape(z_mean)[1]\n",
    "             epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "             return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "    latent_dim = 2\n",
    "    encoder_inputs = tf.keras.Input(shape = (9, 40, 40, 1))\n",
    "\n",
    "    x = tf.keras.layers.Conv3D(64, (2, 3, 3), (1, 1, 1), padding = 'same', activation=\"relu\")(encoder_inputs)\n",
    "    x = tf.keras.layers.Conv3D(64, (2, 3, 3), (1, 1, 1), padding = 'same', activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Conv3D(64, (2, 3, 3), (1, 1, 1), padding = 'same', activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.MaxPooling3D((3, 1, 1))(x)\n",
    "    x = tf.keras.layers.Conv3D(64, (2, 3, 3), (1, 1, 1), padding = 'same', activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.MaxPooling3D((3, 1, 1))(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(16, activation=\"relu\")(x)\n",
    "\n",
    "    z_mean = tf.keras.layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "    z_log_var = tf.keras.layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "    z = Sampling()((z_mean, z_log_var))\n",
    "    encoder = tf.keras.Model(encoder_inputs, z, name=\"encoder\")\n",
    "\n",
    "    latent_inputs = tf.keras.Input(shape=(latent_dim,))\n",
    "    y = tf.keras.layers.Dense(40 * 40 * 64, activation=\"relu\")(latent_inputs)\n",
    "    y = tf.keras.layers.Reshape((1, 40, 40, 64))(y)\n",
    "    y = tf.keras.layers.Conv3DTranspose(filters=64, kernel_size=(1, 3, 3),\n",
    "                                         strides=(1, 1, 1), activation=\"relu\", padding=\"same\")(y)\n",
    "    y = tf.keras.layers.Conv3DTranspose(filters=64, kernel_size=(1, 3, 3),\n",
    "                                         strides=(1, 1, 1), activation=\"relu\", padding=\"same\")(y)\n",
    "    y = tf.keras.layers.Conv3DTranspose(filters=64, kernel_size=(1, 3, 3),\n",
    "                                         strides=(1, 1, 1), activation=\"sigmoid\", padding=\"same\")(y)\n",
    "    decoder_outputs = tf.math.reduce_sum(y, axis = -1)\n",
    "    decoder = tf.keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "    outputs = decoder(z)\n",
    "    vae = tf.keras.Model(inputs=encoder_inputs, outputs=outputs, name=\"vae\")\n",
    "\n",
    "    # Add KL divergence regularization loss.\n",
    "    kl_loss = -0.5 * tf.reduce_mean(z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
    "    vae.add_loss(kl_loss)\n",
    "\n",
    "    # Loss and optimizer.\n",
    "    loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "    # Configure the model for training.\n",
    "    vae.compile(optimizer, loss=loss_fn)\n",
    "\n",
    "    return vae\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e0d027",
   "metadata": {},
   "source": [
    "## Volcanic Encoder Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91b88df",
   "metadata": {},
   "source": [
    "This architecture is produced by following instructions from [Automatic Detection of Volcanic Surface Deformation Using Deep Learning ](https://www.researchgate.net/publication/344212377_Automatic_Detection_of_Volcanic_Surface_Deformation_Using_Deep_Learning).\n",
    "So far, we have not been able to train the model since the kernel dies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "648e2464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def volcanic_encoder_decoder(num_pixels = 40):\n",
    "    model_input = tf.keras.Input(shape=(9, num_pixels , num_pixels , 1))\n",
    "    second_input = tf.keras.Input(shape=(1, num_pixels , num_pixels , 1))\n",
    "\n",
    "    # encoder\n",
    "    x = tf.keras.layers.Conv3D(64, (3, 3, 3), padding='same')(model_input)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.8)(x)\n",
    "    x = tf.keras.layers.Conv3D(64, (3, 3, 3), padding='same')(x)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    x_concat_1 = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.8)(x_concat_1)\n",
    "    x = tf.keras.layers.MaxPooling3D((2, 2, 2), strides=(1, 1, 1))(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv3D(128, (3, 3, 3), padding='same')(x)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.8)(x)\n",
    "    x = tf.keras.layers.Conv3D(128, (3, 3, 3), padding='same')(x)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    x_concat_2 = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.8)(x_concat_2)\n",
    "    x = tf.keras.layers.MaxPooling3D((2, 2, 2), strides=(1, 1, 1))(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv3D(256, (3, 3, 3), padding='same')(x)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.8)(x)\n",
    "    x = tf.keras.layers.Conv3D(256, (3, 3, 3), padding='same')(x)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    x_concat_3 = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.8)(x_concat_3)\n",
    "    x = tf.keras.layers.MaxPooling3D((2, 2, 2), strides=(1, 1, 1))(x)\n",
    "\n",
    "    # bottleneck\n",
    "    x = tf.keras.layers.Conv3D(512, (3, 3, 3), padding='same')(x)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.8)(x)\n",
    "    x = tf.keras.layers.Conv3D(512, (3, 3, 3), padding='same')(x)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.8)(x)\n",
    "\n",
    "    # decoder\n",
    "    x = tf.keras.layers.Conv3DTranspose(256, (2, 2, 2))(x)\n",
    "    x = tf.keras.layers.Conv3D(256, (3, 3, 3), padding='same')(x)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.8)(x)\n",
    "    concat_3 = tf.concat([x, x_concat_3], axis=-1)\n",
    "    x = tf.keras.layers.Conv3D(256, (3, 3, 3), padding='same')(concat_3)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.8)(x)\n",
    "    x = tf.keras.layers.Conv3D(256, (3, 3, 3), padding='same')(x)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.8)(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv3DTranspose(128, (2, 2, 2))(x)\n",
    "    x = tf.keras.layers.Conv3D(128, (3, 3, 3), padding='same')(x)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.8)(x)\n",
    "    concat_2 = tf.concat([x, x_concat_2], axis=-1)\n",
    "    x = tf.keras.layers.Conv3D(128, (3, 3, 3), padding='same')(concat_2)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.8)(x)\n",
    "    x = tf.keras.layers.Conv3D(128, (3, 3, 3), padding='same')(x)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.8)(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv3DTranspose(64, (2, 2, 2))(x)\n",
    "    x = tf.keras.layers.Conv3D(64, (3, 3, 3), padding='same')(x)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.8)(x)\n",
    "    concat_1 = tf.concat([x, x_concat_1], axis=-1)\n",
    "    x = tf.keras.layers.Conv3D(64, (3, 3, 3), padding='same')(concat_1)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.8)(x)\n",
    "    x = tf.keras.layers.Conv3D(64, (3, 3, 3), padding='same')(x)\n",
    "    x = tf.keras.layers.PReLU()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    model_output = tf.keras.layers.Dropout(0.8)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[model_input, second_input], outputs=model_output,\n",
    "                                  name=\"volcanic_encoder_decoder\")\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
